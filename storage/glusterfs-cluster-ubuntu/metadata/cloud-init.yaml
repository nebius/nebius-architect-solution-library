#cloud-config
package_update: true
#ssh_pwauth: no
packages:
  - glusterfs-server
users:
  - name: storage
    groups: sudo
    shell: /bin/bash
    sudo: ["ALL=(ALL) NOPASSWD:ALL"]
    ssh-authorized-keys:
      - ${master_pubkey}
      - ${local_pubkey}
  - name: root
    groups: sudo
    shell: /bin/bash
    sudo: ["ALL=(ALL) NOPASSWD:ALL"]
    ssh-authorized-keys:
      - ${master_pubkey}
      - ${local_pubkey}

write_files:
  - content: |
%{ for line in master_privkey ~}
      ${line}
%{ endfor ~}
    path: /root/.ssh/id_ed25519
    permissions: "0400"
    owner: root:root

runcmd:
  - mkfs.xfs -f -i size=512 /dev/vdb
  - mkdir -p /bricks/brick1
  - [ sh, -c, echo '/dev/vdb /bricks/brick1 xfs defaults 1 2' >> /etc/fstab ]
  - mount -a
  - systemctl enable glusterd
  - systemctl start glusterd
  - |
    if [ "$(hostname)" = "gluster01" ]; then
      sleep 1m
      result=""
      i=1
      while [ $i -le ${nodes_count} ]; do
        gluster peer probe gluster$(printf "%02d" $i)
        result="gluster$(printf "%02d" $i):/bricks/brick1/vol0 $result"
        i=$((i + 1))
      done
      gluster volume create stripe-volume $(echo "$result" | sed 's/ $//')
      gluster volume set stripe-volume client.event-threads 8
      gluster volume set stripe-volume server.event-threads 8
      gluster volume set stripe-volume performance.read-ahead-page-count 16
      gluster volume set stripe-volume performance.client-io-threads on
      gluster volume set stripe-volume performance.quick-read off
      gluster volume set stripe-volume performance.parallel-readdir on
      gluster volume set stripe-volume performance.io-thread-count 32
      gluster volume set stripe-volume performance.cache-size 1GB
      gluster volume set stripe-volume server.allow-insecure on
      gluster volume start stripe-volume
    fi
