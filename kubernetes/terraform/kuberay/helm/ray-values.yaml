additionalWorkerGroups:
  cpu:
    affinity:
      nodeAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
        - weight: 100
          preference:
            matchExpressions:
            - key: beta.kubernetes.io/instance-type
              operator: In
              values:
              - standard-v2
    annotations: {}
    args: []
    command: []
    containerEnv: []
    disabled: false
    envFrom: []
    labels: {}
    maxReplicas: 0
    minReplicas: 0
    nodeSelector: 
      beta.kubernetes.io/instance-type: standard-v2
    rayStartParams: {}
    replicas: 0
    resources:
      limits:
        cpu: "16"
        memory: 30Gi
      requests:
        cpu: '{{ .Values.additionalWorkerGroups.cpu.resources.limits.cpu }}'
        memory: '{{ .Values.additionalWorkerGroups.cpu.resources.limits.memory }}'
    securityContext: {}
    serviceAccountName: ""
    sidecarContainers: []
    tolerations: []
    volumeMounts:
    - mountPath: /tmp/ray
      name: log-volume
    volumes:
    - emptyDir: {}
      name: log-volume
    tolerations:
    - key: "beta.kubernetes.io/instance-type"
      operator: "Equal"
      value: "standard-v2"
      effect: "NoSchedule"
common:
  containerEnv:
  - name: AWS_EC2_METADATA_DISABLED
    value: "TRUE"
customImage: null
fullnameOverride: ""
gpuPlatform: NVIDIA® H100 NVLink with Intel Sapphire Rapids
gpuToResourceHelperValues:
  NVIDIA® H100 NVLink with Intel Sapphire Rapids:
    cpu: 20
    memory: 160
  NVIDIA® H100 PCIe with Intel Ice Lake:
    cpu: 22
    memory: 86
  NVIDIA® V100 NVLink with Intel Cascade Lake:
    cpu: 7
    memory: 40
  NVIDIA® V100 PCIe with Intel Broadwell:
    cpu: 3
    memory: 40
worker:
  annotations: {}
  args: []
  command: []
  containerEnv: []
  envFrom: []
  groupName: gpu
  labels: {}
  maxReplicas: 
  minReplicas: 
  nodeSelector: {}
  rayStartParams: {}
  replicas: 1
  resources:
    limits:
      cpu: '{{ (get .Values.gpuToResourceHelperValues .Values.gpuPlatform).cpu }}'
      memory: '{{ (get .Values.gpuToResourceHelperValues .Values.gpuPlatform).memory
        }}Gi'
      nvidia.com/gpu: "8"
    requests:
      cpu: '{{ tpl .Values.worker.resources.limits.cpu . }}'
      memory: '{{ tpl .Values.worker.resources.limits.memory . }}'
      nvidia.com/gpu: "8"
  nodeSelector: 
    beta.kubernetes.io/instance-type: gpu-h100-b
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: beta.kubernetes.io/instance-type
            operator: In
            values:
            - gpu-h100-b
  securityContext:
    privileged: true
  serviceAccountName: ""
  sidecarContainers: []
  tolerations:
  - effect: NoSchedule
    key: nvidia.com/gpu
    operator: Exists
  volumeMounts:
  - mountPath: /tmp/ray
    name: log-volume
  volumes:
  - emptyDir: {}
    name: log-volume
  - name: node-mount
    hostPath:
      path: /shared
      type: Directory
head:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: beta.kubernetes.io/instance-type
            operator: In
            values:
            - standard-v2
  annotations: {}
  args: []
  command: []
  containerEnv:
  - name: RAY_REDIS_ADDRESS
    value: '{{ .Release.Name }}-redis-master:6379'
  - name: NVIDIA_VISIBLE_DEVICES
    value: "void"
  enableInTreeAutoscaling: true
  envFrom: []
  headService: {}
  labels: {}
  nodeSelector: 
    beta.kubernetes.io/instance-type: standard-v2
  tolerations:
  - key: "beta.kubernetes.io/instance-type"
    operator: "Equal"
    value: "standard-v2"
    effect: "NoSchedule"
  rayStartParams:
    dashboard-host: 0.0.0.0
  resources:
    limits:
      cpu: "4"
      memory: 8Gi
    requests:
      cpu: '{{ .Values.head.resources.limits.cpu }}'
      memory: '{{ .Values.head.resources.limits.memory }}'
  securityContext: {}
  serviceAccountName: ""
  sidecarContainers: []
  volumeMounts:
  - mountPath: /tmp/ray
    name: log-volume
  - mountPath: /shared
    name: node-mount
  volumes:
  - emptyDir: {}
    name: log-volume
  - name: node-mount
    hostPath:
      path: /shared
      type: Directory
image:
  pullPolicy: IfNotPresent
  repository: cr.nemax.nebius.cloud/yc-marketplace/nebius/ray-cluster/rayproject/ray-ml1713900777304275129011842529120435612759099215098
  tag: 2.9.3-gpu
imagePullSecrets: []
kuberay-operator:
  affinity:
    nodeAffinity:
      requiredDuringSchedulingIgnoredDuringExecution:
        nodeSelectorTerms:
        - matchExpressions:
          - key: beta.kubernetes.io/instance-type
            operator: NotIn
            values:
            - gpu-h100-b
  image:
    pullPolicy: IfNotPresent
    repository: cr.nemax.nebius.cloud/yc-marketplace/nebius/ray-cluster/kuberay/operator1713900777304275129011842529120435612759099215098
    tag: v1.1.0
  singleNamespaceInstall: true
  nodeSelector: 
    beta.kubernetes.io/instance-type: standard-v2
nameOverride: kuberay
redis:
  affinity:
    nodeAffinity:
      preferredDuringSchedulingIgnoredDuringExecution:
      - weight: 100
        preference:
          matchExpressions:
          - key: beta.kubernetes.io/instance-type
            operator: In
            values:
            - standard-v2
  architecture: standalone
  auth:
    enabled: false
  image:
    pullPolicy: IfNotPresent
    registry: cr.nemax.nebius.cloud/yc-marketplace
    repository: nebius/ray-cluster/redis1713900777304275129011842529120435612759099215098
    tag: 7.2.4-debian-12-r9
  master:
    persistence:
      size: 8Gi
      storageClass: nebius-network-ssd
    persistentVolumeClaimRetentionPolicy:
      enabled: true
      whenDeleted: Delete
      whenScaled: Retain
    resources:
      limits:
        cpu: "2" # limits Minimum cpu=4 per gpu node
        memory: 4Gi # limits Minimum memory=8Gi per gpu node
      requests:
        cpu: "1" # Requests Minimum cpu=1 per gpu node
        memory: 512Mi # Requests Minimum memory=512Mi per gpu node
    serviceAccount:
      create: false
  networkPolicy:
    enabled: false
  serviceAccount:
    create: false
  nodeSelector:
    beta.kubernetes.io/instance-type: standard-v2
service:
  type: ClusterIP
